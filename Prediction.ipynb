{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456ddd4f-465b-4c33-8aae-c7fcc991bb26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ryzen\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from hyperopt import Trials, STATUS_OK, tpe, fmin, hp\n",
    "import time\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c1543b-05b8-47a9-8288-7402a3f8cb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0568c835-afc2-42e7-ac4d-99fd8d153eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 이상치 판단\n",
    "def outlier(data, column):\n",
    "    q25 = np.quantile(data[column].dropna(), 0.25)\n",
    "    q75 = np.quantile(data[column].dropna(), 0.75)\n",
    "    iqr = q75 - q25\n",
    "    iqr_cut = iqr * 3\n",
    "    result = data[(data[column] > q75 + iqr_cut) | (data[column] < q25 - iqr_cut)].index\n",
    "    return result\n",
    "\n",
    "# 보간\n",
    "def time_interpolate(data, column):\n",
    "    tem = data[[\"일시\", column]].copy()\n",
    "    tem.index = pd.to_datetime(tem['일시'])\n",
    "    tem = tem.drop([\"일시\"], axis = 1)\n",
    "    tem = tem.interpolate(method=\"time\")\n",
    "    return tem[column].values\n",
    "\n",
    "# 강수량은 기상청에서 정한 강수표현에 따라 구간을 나누는 것으로 수치 변경\n",
    "# 비가 내리지 않음 : 0, 매우 약한 비 : 0~1, 약한 비 : 1~3, 보통 비 : 3~15, 강한 비 : 15~30, 매우 강한 비 : 30 이상\n",
    "train.강수량 = pd.cut(train.강수량, bins = [0, 0.9, 2.9, 14.9, 29.9, max(train.강수량)], labels = [1, 2, 3, 4, 5])\n",
    "train.강수량 = train.강수량.astype('float')\n",
    "train.강수량 = train.강수량.fillna(0)\n",
    "\n",
    "rain = pd.get_dummies(train.강수량)\n",
    "rain.columns = [\"비안내림\", \"매우약한비\", \"약한비\", \"보통비\", \"강한비\", \"매우강한비\"]\n",
    "train = pd.concat([train, rain.astype(\"int\")], axis=1)\n",
    "train = train.drop([\"강수량\"], axis = 1)\n",
    "\n",
    "train.최고기온 = time_interpolate(train, \"최고기온\")\n",
    "train.최저기온 = time_interpolate(train, \"최저기온\")\n",
    "\n",
    "train.일교차 = train.최고기온 - train.최저기온\n",
    "\n",
    "train.평균풍속 = time_interpolate(train, \"평균풍속\")\n",
    "\n",
    "train.일조합 = time_interpolate(train, \"일조합\")\n",
    "\n",
    "train.loc[0:4749, \"일사합\"] = 0\n",
    "train.loc[4780:4854, \"일사합\"] = 0\n",
    "train.일사합 = time_interpolate(train, \"일사합\")\n",
    "\n",
    "\n",
    "# 삭제\n",
    "train = train.iloc[train.일조율.dropna().index]\n",
    "\n",
    "# 가조합\n",
    "train[\"가조합\"] = train.일조합/(train.일조율/100)\n",
    "train.가조합 = [np.nan if i == float(\"inf\") else i for i in train.가조합]\n",
    "train.가조합 = time_interpolate(train, \"가조합\")\n",
    "\n",
    "# 일사합/일조합\n",
    "train[\"일사_일조\"] = train.일사합/train.일조합\n",
    "train.일사_일조 = [np.nan if i == float(\"inf\") else i for i in train.일사_일조] # 분모가 0인 경우 임의로 값을 설정할 수 없어 보간으로 처리\n",
    "train.일사_일조 = time_interpolate(train, \"일사_일조\")\n",
    "\n",
    "# sin + cos\n",
    "train[\"sin_cos\"] = [-np.sin(2 * np.pi * int(datetime.strptime(i,\"%Y-%m-%d\").strftime(\"%j\"))/365) - np.cos(2 * np.pi * int(datetime.strptime(i,\"%Y-%m-%d\").strftime(\"%j\"))/365) for i in train.일시]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04246ee7-9bb9-4320-874f-fb7643c546be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.일시 = train.일시.str.split(\"-\", expand = True)[0].astype(\"int\")\n",
    "train = train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d2e1b8-c05e-42ef-bfa6-19f50a522e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year = [1980, 1990, 2000, 2005, 2010, 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a65aa5e7-1f2e-4196-b2a3-842202dfff04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6939, 10592, 14244, 16071, 17897, 19723]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = []\n",
    "for i in year:\n",
    "    idx.append(train[train.일시 == i].index[0])\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59587718-d311-4071-8172-261ad55ec36d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop([\"일시\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2060faaa-dfe0-4852-83c0-4e42667c28e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22645 entries, 0 to 22644\n",
      "Data columns (total 18 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   최고기온     22645 non-null  float64\n",
      " 1   최저기온     22645 non-null  float64\n",
      " 2   일교차      22645 non-null  float64\n",
      " 3   평균습도     22645 non-null  float64\n",
      " 4   평균풍속     22645 non-null  float64\n",
      " 5   일조합      22645 non-null  float64\n",
      " 6   일사합      22645 non-null  float64\n",
      " 7   일조율      22645 non-null  float64\n",
      " 8   평균기온     22645 non-null  float64\n",
      " 9   비안내림     22645 non-null  int32  \n",
      " 10  매우약한비    22645 non-null  int32  \n",
      " 11  약한비      22645 non-null  int32  \n",
      " 12  보통비      22645 non-null  int32  \n",
      " 13  강한비      22645 non-null  int32  \n",
      " 14  매우강한비    22645 non-null  int32  \n",
      " 15  가조합      22645 non-null  float64\n",
      " 16  일사_일조    22645 non-null  float64\n",
      " 17  sin_cos  22645 non-null  float64\n",
      "dtypes: float64(12), int32(6)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "# 결측치 없음\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aa7b456-a3bd-4463-93c2-d138d8e0d727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, data, target, input_size, output_size, test_size):\n",
    "        self.data = data\n",
    "        self.target = target        \n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        self.col_len = len(self.data.columns)\n",
    "\n",
    "def Scale(self, data):\n",
    "    scaler_in = MinMaxScaler()\n",
    "    scaler_out = MinMaxScaler()\n",
    "    \n",
    "    inputs = data.drop(self.target, axis = 1)\n",
    "    inputs_col = inputs.columns\n",
    "    outputs = data[self.target]\n",
    "    \n",
    "    scaler_in.fit(inputs)\n",
    "    inputs = pd.DataFrame(scaler_in.transform(inputs), columns = inputs_col)\n",
    "        \n",
    "    scaler_out.fit(outputs)\n",
    "    outputs = pd.DataFrame(scaler_out.fit_transform(outputs), columns = self.target)\n",
    "\n",
    "    data = pd.concat([inputs, outputs], axis = 1)\n",
    "    \n",
    "    return data,  scaler_out\n",
    "\n",
    "def Split(self, data):\n",
    "    data, _ = self.Scale(data)\n",
    "    data = tf.keras.utils.timeseries_dataset_from_array(data = data,\n",
    "                                                             targets = None,\n",
    "                                                             sequence_length = self.input_size + self.output_size)\n",
    "    inputs = np.concatenate([x[:, slice(0, self.input_size), :] for x in data], axis=0)\n",
    "    outputs = np.concatenate([x[:, slice(self.input_size, self.input_size + self.output_size), :] for x in data], axis=0)\n",
    "\n",
    "    outputs = outputs[:,:,self.col_len-1]\n",
    "    outputs = outputs.reshape(-1, self.output_size, 1)\n",
    "    \n",
    "    train_in = inputs[:int(len(inputs)*0.8), :, :]\n",
    "    train_out = outputs[:int(len(outputs)*0.8), :, :]\n",
    "    \n",
    "    test_in = inputs[int(len(inputs)*0.8):, :, :]\n",
    "    test_out = outputs[int(len(outputs)*0.8):, :, :]\n",
    "    \n",
    "    return train_in, train_out, test_in, test_out\n",
    "\n",
    "@property\n",
    "def Data(self):\n",
    "    return self.Split(self.data)\n",
    "\n",
    "Model.Scale = Scale\n",
    "Model.Split = Split\n",
    "Model.Data = Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d24f1987-7d3c-43a8-98b2-65bb96d60638",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "------------------------------[ 1980 ] ---------------------------------------\n",
      "Epoch 1/100\n",
      "366/366 [==============================] - 468s 1s/step - loss: 0.0898 - mean_absolute_error: 0.0898 - val_loss: 0.0564 - val_mean_absolute_error: 0.0564\n",
      "Epoch 2/100\n",
      "366/366 [==============================] - 453s 1s/step - loss: 0.0508 - mean_absolute_error: 0.0508 - val_loss: 0.0533 - val_mean_absolute_error: 0.0533\n",
      "Epoch 3/100\n",
      "366/366 [==============================] - 465s 1s/step - loss: 0.0504 - mean_absolute_error: 0.0504 - val_loss: 0.0531 - val_mean_absolute_error: 0.0531\n",
      "Epoch 4/100\n",
      "366/366 [==============================] - 481s 1s/step - loss: 0.0500 - mean_absolute_error: 0.0500 - val_loss: 0.0517 - val_mean_absolute_error: 0.0517\n",
      "Epoch 5/100\n",
      "366/366 [==============================] - 467s 1s/step - loss: 0.0498 - mean_absolute_error: 0.0498 - val_loss: 0.0530 - val_mean_absolute_error: 0.0530\n",
      "Epoch 6/100\n",
      "366/366 [==============================] - 483s 1s/step - loss: 0.0495 - mean_absolute_error: 0.0495 - val_loss: 0.0532 - val_mean_absolute_error: 0.0532\n",
      "Epoch 7/100\n",
      "366/366 [==============================] - 476s 1s/step - loss: 0.0492 - mean_absolute_error: 0.0492 - val_loss: 0.0520 - val_mean_absolute_error: 0.0520\n",
      "Epoch 8/100\n",
      "366/366 [==============================] - 484s 1s/step - loss: 0.0489 - mean_absolute_error: 0.0489 - val_loss: 0.0525 - val_mean_absolute_error: 0.0525\n",
      "Epoch 9/100\n",
      "366/366 [==============================] - 483s 1s/step - loss: 0.0487 - mean_absolute_error: 0.0487 - val_loss: 0.0513 - val_mean_absolute_error: 0.0513\n",
      "Epoch 10/100\n",
      "366/366 [==============================] - 451s 1s/step - loss: 0.0481 - mean_absolute_error: 0.0481 - val_loss: 0.0524 - val_mean_absolute_error: 0.0524\n",
      "Epoch 11/100\n",
      "366/366 [==============================] - 436s 1s/step - loss: 0.0477 - mean_absolute_error: 0.0477 - val_loss: 0.0525 - val_mean_absolute_error: 0.0525\n",
      "Epoch 12/100\n",
      "366/366 [==============================] - 441s 1s/step - loss: 0.0471 - mean_absolute_error: 0.0471 - val_loss: 0.0524 - val_mean_absolute_error: 0.0524\n",
      "Epoch 13/100\n",
      "366/366 [==============================] - 457s 1s/step - loss: 0.0467 - mean_absolute_error: 0.0467 - val_loss: 0.0536 - val_mean_absolute_error: 0.0536\n",
      "Epoch 14/100\n",
      "366/366 [==============================] - 471s 1s/step - loss: 0.0465 - mean_absolute_error: 0.0465 - val_loss: 0.0536 - val_mean_absolute_error: 0.0536\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "----------------------------------------------------------------------------\n",
      "------------------------------[ 1990 ] ---------------------------------------\n",
      "Epoch 1/100\n",
      "275/275 [==============================] - 332s 1s/step - loss: 0.1116 - mean_absolute_error: 0.1116 - val_loss: 0.0587 - val_mean_absolute_error: 0.0587\n",
      "Epoch 2/100\n",
      "275/275 [==============================] - 341s 1s/step - loss: 0.0525 - mean_absolute_error: 0.0525 - val_loss: 0.0553 - val_mean_absolute_error: 0.0553\n",
      "Epoch 3/100\n",
      "275/275 [==============================] - 351s 1s/step - loss: 0.0519 - mean_absolute_error: 0.0519 - val_loss: 0.0539 - val_mean_absolute_error: 0.0539\n",
      "Epoch 4/100\n",
      "275/275 [==============================] - 359s 1s/step - loss: 0.0515 - mean_absolute_error: 0.0515 - val_loss: 0.0539 - val_mean_absolute_error: 0.0539\n",
      "Epoch 5/100\n",
      "275/275 [==============================] - 342s 1s/step - loss: 0.0512 - mean_absolute_error: 0.0512 - val_loss: 0.0544 - val_mean_absolute_error: 0.0544\n",
      "Epoch 6/100\n",
      "275/275 [==============================] - 339s 1s/step - loss: 0.0512 - mean_absolute_error: 0.0512 - val_loss: 0.0539 - val_mean_absolute_error: 0.0539\n",
      "Epoch 7/100\n",
      "275/275 [==============================] - 345s 1s/step - loss: 0.0509 - mean_absolute_error: 0.0509 - val_loss: 0.0540 - val_mean_absolute_error: 0.0540\n",
      "Epoch 8/100\n",
      "275/275 [==============================] - 363s 1s/step - loss: 0.0507 - mean_absolute_error: 0.0507 - val_loss: 0.0529 - val_mean_absolute_error: 0.0529\n",
      "Epoch 9/100\n",
      "275/275 [==============================] - 363s 1s/step - loss: 0.0505 - mean_absolute_error: 0.0505 - val_loss: 0.0529 - val_mean_absolute_error: 0.0529\n",
      "Epoch 10/100\n",
      "275/275 [==============================] - 363s 1s/step - loss: 0.0504 - mean_absolute_error: 0.0504 - val_loss: 0.0531 - val_mean_absolute_error: 0.0531\n",
      "Epoch 11/100\n",
      "275/275 [==============================] - 362s 1s/step - loss: 0.0501 - mean_absolute_error: 0.0501 - val_loss: 0.0534 - val_mean_absolute_error: 0.0534\n",
      "Epoch 12/100\n",
      "275/275 [==============================] - 325s 1s/step - loss: 0.0503 - mean_absolute_error: 0.0503 - val_loss: 0.0544 - val_mean_absolute_error: 0.0544\n",
      "Epoch 13/100\n",
      "275/275 [==============================] - 326s 1s/step - loss: 0.0499 - mean_absolute_error: 0.0499 - val_loss: 0.0529 - val_mean_absolute_error: 0.0529\n",
      "Epoch 14/100\n",
      "275/275 [==============================] - 327s 1s/step - loss: 0.0497 - mean_absolute_error: 0.0497 - val_loss: 0.0542 - val_mean_absolute_error: 0.0542\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "----------------------------------------------------------------------------\n",
      "------------------------------[ 2000 ] ---------------------------------------\n",
      "Epoch 1/100\n",
      "184/184 [==============================] - 229s 1s/step - loss: 0.1385 - mean_absolute_error: 0.1385 - val_loss: 0.0578 - val_mean_absolute_error: 0.0578\n",
      "Epoch 2/100\n",
      "184/184 [==============================] - 238s 1s/step - loss: 0.0545 - mean_absolute_error: 0.0545 - val_loss: 0.0556 - val_mean_absolute_error: 0.0556\n",
      "Epoch 3/100\n",
      "184/184 [==============================] - 236s 1s/step - loss: 0.0526 - mean_absolute_error: 0.0526 - val_loss: 0.0544 - val_mean_absolute_error: 0.0544\n",
      "Epoch 4/100\n",
      "184/184 [==============================] - 238s 1s/step - loss: 0.0526 - mean_absolute_error: 0.0526 - val_loss: 0.0558 - val_mean_absolute_error: 0.0558\n",
      "Epoch 5/100\n",
      "184/184 [==============================] - 250s 1s/step - loss: 0.0521 - mean_absolute_error: 0.0521 - val_loss: 0.0555 - val_mean_absolute_error: 0.0555\n",
      "Epoch 6/100\n",
      "184/184 [==============================] - 250s 1s/step - loss: 0.0515 - mean_absolute_error: 0.0515 - val_loss: 0.0548 - val_mean_absolute_error: 0.0548\n",
      "Epoch 7/100\n",
      "184/184 [==============================] - 235s 1s/step - loss: 0.0513 - mean_absolute_error: 0.0513 - val_loss: 0.0543 - val_mean_absolute_error: 0.0543\n",
      "Epoch 8/100\n",
      "184/184 [==============================] - 225s 1s/step - loss: 0.0513 - mean_absolute_error: 0.0513 - val_loss: 0.0543 - val_mean_absolute_error: 0.0543\n",
      "Epoch 9/100\n",
      "184/184 [==============================] - 225s 1s/step - loss: 0.0507 - mean_absolute_error: 0.0507 - val_loss: 0.0538 - val_mean_absolute_error: 0.0538\n",
      "Epoch 10/100\n",
      "184/184 [==============================] - 224s 1s/step - loss: 0.0507 - mean_absolute_error: 0.0507 - val_loss: 0.0540 - val_mean_absolute_error: 0.0540\n",
      "Epoch 11/100\n",
      "184/184 [==============================] - 224s 1s/step - loss: 0.0505 - mean_absolute_error: 0.0505 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
      "Epoch 12/100\n",
      "184/184 [==============================] - 226s 1s/step - loss: 0.0499 - mean_absolute_error: 0.0499 - val_loss: 0.0542 - val_mean_absolute_error: 0.0542\n",
      "Epoch 13/100\n",
      "184/184 [==============================] - 225s 1s/step - loss: 0.0496 - mean_absolute_error: 0.0496 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562\n",
      "Epoch 14/100\n",
      "184/184 [==============================] - 223s 1s/step - loss: 0.0491 - mean_absolute_error: 0.0491 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "----------------------------------------------------------------------------\n",
      "------------------------------[ 2005 ] ---------------------------------------\n",
      "Epoch 1/100\n",
      "138/138 [==============================] - 184s 1s/step - loss: 0.1641 - mean_absolute_error: 0.1641 - val_loss: 0.0656 - val_mean_absolute_error: 0.0656\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - 174s 1s/step - loss: 0.0562 - mean_absolute_error: 0.0562 - val_loss: 0.0575 - val_mean_absolute_error: 0.0575\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - 175s 1s/step - loss: 0.0533 - mean_absolute_error: 0.0533 - val_loss: 0.0554 - val_mean_absolute_error: 0.0554\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - 175s 1s/step - loss: 0.0526 - mean_absolute_error: 0.0526 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - 175s 1s/step - loss: 0.0527 - mean_absolute_error: 0.0527 - val_loss: 0.0588 - val_mean_absolute_error: 0.0588\n",
      "Epoch 6/100\n",
      "138/138 [==============================] - 175s 1s/step - loss: 0.0525 - mean_absolute_error: 0.0525 - val_loss: 0.0553 - val_mean_absolute_error: 0.0553\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - 175s 1s/step - loss: 0.0520 - mean_absolute_error: 0.0520 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - 175s 1s/step - loss: 0.0520 - mean_absolute_error: 0.0520 - val_loss: 0.0556 - val_mean_absolute_error: 0.0556\n",
      "Epoch 9/100\n",
      "138/138 [==============================] - 174s 1s/step - loss: 0.0521 - mean_absolute_error: 0.0521 - val_loss: 0.0552 - val_mean_absolute_error: 0.0552\n",
      "Epoch 10/100\n",
      "138/138 [==============================] - 174s 1s/step - loss: 0.0519 - mean_absolute_error: 0.0519 - val_loss: 0.0550 - val_mean_absolute_error: 0.0550\n",
      "Epoch 11/100\n",
      "138/138 [==============================] - 175s 1s/step - loss: 0.0516 - mean_absolute_error: 0.0516 - val_loss: 0.0551 - val_mean_absolute_error: 0.0551\n",
      "Epoch 12/100\n",
      "138/138 [==============================] - 184s 1s/step - loss: 0.0512 - mean_absolute_error: 0.0512 - val_loss: 0.0566 - val_mean_absolute_error: 0.0566\n",
      "Epoch 13/100\n",
      "138/138 [==============================] - 175s 1s/step - loss: 0.0512 - mean_absolute_error: 0.0512 - val_loss: 0.0557 - val_mean_absolute_error: 0.0557\n",
      "Epoch 14/100\n",
      "138/138 [==============================] - 175s 1s/step - loss: 0.0508 - mean_absolute_error: 0.0508 - val_loss: 0.0553 - val_mean_absolute_error: 0.0553\n",
      "Epoch 15/100\n",
      "138/138 [==============================] - 175s 1s/step - loss: 0.0508 - mean_absolute_error: 0.0508 - val_loss: 0.0556 - val_mean_absolute_error: 0.0556\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002326D6DA0C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "----------------------------------------------------------------------------\n",
      "------------------------------[ 2010 ] ---------------------------------------\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 132s 1s/step - loss: 0.2113 - mean_absolute_error: 0.2113 - val_loss: 0.1360 - val_mean_absolute_error: 0.1360\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 126s 1s/step - loss: 0.0947 - mean_absolute_error: 0.0947 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 126s 1s/step - loss: 0.0567 - mean_absolute_error: 0.0567 - val_loss: 0.0609 - val_mean_absolute_error: 0.0609\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 126s 1s/step - loss: 0.0528 - mean_absolute_error: 0.0528 - val_loss: 0.0581 - val_mean_absolute_error: 0.0581\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 125s 1s/step - loss: 0.0515 - mean_absolute_error: 0.0515 - val_loss: 0.0582 - val_mean_absolute_error: 0.0582\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 125s 1s/step - loss: 0.0513 - mean_absolute_error: 0.0513 - val_loss: 0.0575 - val_mean_absolute_error: 0.0575\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 124s 1s/step - loss: 0.0509 - mean_absolute_error: 0.0509 - val_loss: 0.0571 - val_mean_absolute_error: 0.0571\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 125s 1s/step - loss: 0.0510 - mean_absolute_error: 0.0510 - val_loss: 0.0568 - val_mean_absolute_error: 0.0568\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 127s 1s/step - loss: 0.0507 - mean_absolute_error: 0.0507 - val_loss: 0.0573 - val_mean_absolute_error: 0.0573\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 115s 1s/step - loss: 0.0506 - mean_absolute_error: 0.0506 - val_loss: 0.0564 - val_mean_absolute_error: 0.0564\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 112s 1s/step - loss: 0.0503 - mean_absolute_error: 0.0503 - val_loss: 0.0570 - val_mean_absolute_error: 0.0570\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 112s 1s/step - loss: 0.0502 - mean_absolute_error: 0.0502 - val_loss: 0.0579 - val_mean_absolute_error: 0.0579\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 113s 1s/step - loss: 0.0502 - mean_absolute_error: 0.0502 - val_loss: 0.0570 - val_mean_absolute_error: 0.0570\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 113s 1s/step - loss: 0.0500 - mean_absolute_error: 0.0500 - val_loss: 0.0572 - val_mean_absolute_error: 0.0572\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 125s 1s/step - loss: 0.0498 - mean_absolute_error: 0.0498 - val_loss: 0.0571 - val_mean_absolute_error: 0.0571\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000232540E6FC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "----------------------------------------------------------------------------\n",
      "------------------------------[ 2015 ] ---------------------------------------\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 64s 1s/step - loss: 0.2447 - mean_absolute_error: 0.2447 - val_loss: 0.1907 - val_mean_absolute_error: 0.1907\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 60s 1s/step - loss: 0.1569 - mean_absolute_error: 0.1569 - val_loss: 0.1201 - val_mean_absolute_error: 0.1201\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 60s 1s/step - loss: 0.0784 - mean_absolute_error: 0.0784 - val_loss: 0.0689 - val_mean_absolute_error: 0.0689\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 60s 1s/step - loss: 0.0585 - mean_absolute_error: 0.0585 - val_loss: 0.0598 - val_mean_absolute_error: 0.0598\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 60s 1s/step - loss: 0.0572 - mean_absolute_error: 0.0572 - val_loss: 0.0565 - val_mean_absolute_error: 0.0565\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 60s 1s/step - loss: 0.0549 - mean_absolute_error: 0.0549 - val_loss: 0.0569 - val_mean_absolute_error: 0.0569\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 60s 1s/step - loss: 0.0542 - mean_absolute_error: 0.0542 - val_loss: 0.0572 - val_mean_absolute_error: 0.0572\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 60s 1s/step - loss: 0.0541 - mean_absolute_error: 0.0541 - val_loss: 0.0573 - val_mean_absolute_error: 0.0573\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 60s 1s/step - loss: 0.0542 - mean_absolute_error: 0.0542 - val_loss: 0.0558 - val_mean_absolute_error: 0.0558\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0534 - mean_absolute_error: 0.0534 - val_loss: 0.0542 - val_mean_absolute_error: 0.0542\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 67s 1s/step - loss: 0.0535 - mean_absolute_error: 0.0535 - val_loss: 0.0591 - val_mean_absolute_error: 0.0591\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 67s 1s/step - loss: 0.0537 - mean_absolute_error: 0.0537 - val_loss: 0.0559 - val_mean_absolute_error: 0.0559\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 67s 1s/step - loss: 0.0542 - mean_absolute_error: 0.0542 - val_loss: 0.0574 - val_mean_absolute_error: 0.0574\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 67s 1s/step - loss: 0.0536 - mean_absolute_error: 0.0536 - val_loss: 0.0552 - val_mean_absolute_error: 0.0552\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 64s 1s/step - loss: 0.0535 - mean_absolute_error: 0.0535 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# train 길이 결정\n",
    "Year_loss = pd.DataFrame([], columns = [\"Year\", \"MAE\"])\n",
    "for i in range(len(idx)):\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------[ {} ] ---------------------------------------\".format(year[i]))\n",
    "    train_c = train.copy()\n",
    "    train_c = train_c.iloc[idx[i]:]\n",
    "    \n",
    "    output_size = 358\n",
    "    model = Model(data = train_c,\n",
    "         target = [\"평균기온\"],\n",
    "         input_size = output_size * 2,\n",
    "         output_size = output_size,\n",
    "         test_size = 0.3)\n",
    "    train_in, train_out, test_in, test_out = model.Data\n",
    "    \n",
    "    lstm_model, history = LSTM_fit(model.Data)\n",
    "    \n",
    "    _, _, test_in, _ = model.Split(train_c)\n",
    "    _, scaler_out = model.Scale(train_c)\n",
    "    pred = lstm_model.predict(test_in[-1].reshape(1, (output_size*2), len(train_c.columns)))\n",
    "    pred = np.round(scaler_out.inverse_transform(pred))\n",
    "    \n",
    "    \n",
    "    mae = mean_absolute_error(train_c.iloc[-output_size:].평균기온.values, pred.reshape(-1))\n",
    "    \n",
    "    Year_loss.loc[len(Year_loss)] = [year[i],mae]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf8ed878-cd33-4571-ba78-b83f6c72d4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>2.975140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>2.913687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>2.740503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>2.615363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>2.631564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.715363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year       MAE\n",
       "0  1980.0  2.975140\n",
       "1  1990.0  2.913687\n",
       "2  2000.0  2.740503\n",
       "3  2005.0  2.615363\n",
       "4  2010.0  2.631564\n",
       "5  2015.0  2.715363"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2005년으로 결정\n",
    "Year_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f0cbce-a6df-4682-b8fb-a370abfae4d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.iloc[idx[3]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4339ac33-8d78-43df-b938-5159c2eadf51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_size = 358\n",
    "space = {\n",
    "    'input_size' : hp.choice(\"input_size\", [output_size, output_size*2, output_size*3]),\n",
    "    'lstm1_nodes' : hp.choice(\"lstm1_nodes\", [64, 128, 256]),\n",
    "    'lstm1_dropout' : hp.choice(\"lstm1_dropout\", [0, 0.3, 0.5]),\n",
    "    'lstm2_nodes' : hp.choice('lstm2_nodes', [64, 128, 256]),\n",
    "    'lstm2_dropout' : hp.choice(\"lstm2_dropout\", [0, 0.3, 0.5]),\n",
    "    'num_layers' : hp.choice('num_layers',[\n",
    "        { \n",
    "            'layers' : 'two',\n",
    "        },\n",
    "        {\n",
    "            'layers' : 'three',\n",
    "            'lstm3_nodes' : hp.choice('lstm3_nodes', [32, 64, 128]),\n",
    "            'lstm3_dropout' : hp.choice(\"lstm3_dropout\", [0, 0.3, 0.5])\n",
    "        }\n",
    "    ]),\n",
    "    'lr' : hp.choice('lr', [0, 0.001, 0.002, 0.003])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a46e225-38ea-4424-87ce-a57f22dda435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Parameter_loss = pd.DataFrame([], columns = [\"Parameters\", \"Loss\"])\n",
    "def hyperopt_model(params):\n",
    "    global Parameter_loss\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"---------------------------------------[ START {}]-------------------------------------------------------------\".format(len(Parameter_loss)))\n",
    "    print(\"Parameter : {}\".format(params))\n",
    "    input_size = params['input_size']\n",
    "    \n",
    "    output_size = 358\n",
    "    model = Model(data = train,\n",
    "         target = [\"평균기온\"],\n",
    "         input_size = params['input_size'],\n",
    "         output_size = output_size,\n",
    "         test_size = 0.3)\n",
    "    \n",
    "    train_in, train_out, test_in, test_out = model.Data\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                                      mode = 'min',\n",
    "                                                      patience = 3,\n",
    "                                                      min_delta = 0.001)\n",
    "    tf.random.set_seed = 1234\n",
    "    initializer = tf.keras.initializers.GlorotUniform(seed=1234)\n",
    "    \n",
    "    lstm_model = tf.keras.Sequential()\n",
    "    lstm_model.add(tf.keras.layers.GRU(params[\"lstm1_nodes\"], \n",
    "                                        dropout = params[\"lstm1_dropout\"],\n",
    "                                        return_sequences = True, \n",
    "                                        kernel_initializer=initializer))\n",
    "    if params[\"num_layers\"][\"layers\"] == \"two\":\n",
    "        lstm_model.add(tf.keras.layers.GRU(params[\"lstm2_nodes\"], \n",
    "                                            dropout = params[\"lstm2_dropout\"],\n",
    "                                            return_sequences = False, \n",
    "                                        kernel_initializer=initializer))\n",
    "    else:\n",
    "        lstm_model.add(tf.keras.layers.GRU(params[\"lstm2_nodes\"], \n",
    "                                            dropout = params[\"lstm2_dropout\"],\n",
    "                                            return_sequences = True, \n",
    "                                        kernel_initializer=initializer))\n",
    "        lstm_model.add(tf.keras.layers.GRU(params[\"num_layers\"][\"lstm3_nodes\"], \n",
    "                                            dropout = params[\"num_layers\"][\"lstm3_dropout\"],\n",
    "                                            return_sequences = False, \n",
    "                                        kernel_initializer=initializer))\n",
    "    lstm_model.add(tf.keras.layers.Dense(output_size, \n",
    "                                        kernel_initializer=initializer))\n",
    "   \n",
    "    lstm_model.compile(loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate = params[\"lr\"]),\n",
    "                      metrics = [tf.keras.metrics.mean_absolute_error])\n",
    "    \n",
    "    history = lstm_model.fit(train_in, train_out,\n",
    "                             epochs = 100,\n",
    "                             validation_data = [test_in, test_out],\n",
    "                             callbacks = [early_stopping],\n",
    "                            verbose = 2)\n",
    "    val_error = np.amin(history.history[\"val_loss\"])\n",
    "    Parameter_loss.loc[len(Parameter_loss)] = [params,val_error]\n",
    "    \n",
    "    print(\"val_error : {}\".format(val_error))\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    return {\"loss\" : val_error, \"model\":lstm_model, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58e6c928-d4fb-4fd2-ab9d-99676038bb4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------[ START 0]-------------------------------------------------------------\n",
      "Parameter : {'input_size': 1074, 'lr': 0, 'lstm1_dropout': 0.3, 'lstm1_nodes': 64, 'lstm2_dropout': 0.5, 'lstm2_nodes': 64, 'num_layers': {'layers': 'two'}}\n",
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:From C:\\Users\\Ryzen\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/100                                          \n",
      "\n",
      "  0%|          | 0/5 [00:02<?, ?trial/s, best loss=?]WARNING:tensorflow:From C:\\Users\\Ryzen\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ryzen\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "129/129 - 81s - loss: 0.5698 - mean_absolute_error: 0.5698 - val_loss: 0.5807 - val_mean_absolute_error: 0.5807 - 81s/epoch - 625ms/step\n",
      "\n",
      "Epoch 2/100                                          \n",
      "\n",
      "129/129 - 82s - loss: 0.5697 - mean_absolute_error: 0.5697 - val_loss: 0.5807 - val_mean_absolute_error: 0.5807 - 82s/epoch - 632ms/step\n",
      "\n",
      "Epoch 3/100                                          \n",
      "\n",
      "129/129 - 68s - loss: 0.5697 - mean_absolute_error: 0.5697 - val_loss: 0.5807 - val_mean_absolute_error: 0.5807 - 68s/epoch - 530ms/step\n",
      "\n",
      "Epoch 4/100                                          \n",
      "\n",
      "129/129 - 70s - loss: 0.5697 - mean_absolute_error: 0.5697 - val_loss: 0.5807 - val_mean_absolute_error: 0.5807 - 70s/epoch - 545ms/step\n",
      "\n",
      "val_error : 0.5807498097419739                       \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------[ START 1]-------------------------------------------------------------\n",
      "Parameter : {'input_size': 1074, 'lr': 0.003, 'lstm1_dropout': 0.5, 'lstm1_nodes': 64, 'lstm2_dropout': 0.5, 'lstm2_nodes': 64, 'num_layers': {'layers': 'two'}}\n",
      "Epoch 1/100                                                                     \n",
      "\n",
      "129/129 - 74s - loss: 0.1269 - mean_absolute_error: 0.1269 - val_loss: 0.0690 - val_mean_absolute_error: 0.0690 - 74s/epoch - 571ms/step\n",
      "\n",
      "Epoch 2/100                                                                     \n",
      "\n",
      "129/129 - 69s - loss: 0.0599 - mean_absolute_error: 0.0599 - val_loss: 0.0632 - val_mean_absolute_error: 0.0632 - 69s/epoch - 537ms/step\n",
      "\n",
      "Epoch 3/100                                                                     \n",
      "\n",
      "129/129 - 69s - loss: 0.0575 - mean_absolute_error: 0.0575 - val_loss: 0.0620 - val_mean_absolute_error: 0.0620 - 69s/epoch - 537ms/step\n",
      "\n",
      "Epoch 4/100                                                                     \n",
      "\n",
      "129/129 - 72s - loss: 0.0557 - mean_absolute_error: 0.0557 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631 - 72s/epoch - 562ms/step\n",
      "\n",
      "Epoch 5/100                                                                     \n",
      "\n",
      "129/129 - 71s - loss: 0.0546 - mean_absolute_error: 0.0546 - val_loss: 0.0592 - val_mean_absolute_error: 0.0592 - 71s/epoch - 548ms/step\n",
      "\n",
      "Epoch 6/100                                                                     \n",
      "\n",
      "129/129 - 71s - loss: 0.0548 - mean_absolute_error: 0.0548 - val_loss: 0.0609 - val_mean_absolute_error: 0.0609 - 71s/epoch - 553ms/step\n",
      "\n",
      "Epoch 7/100                                                                     \n",
      "\n",
      "129/129 - 70s - loss: 0.0539 - mean_absolute_error: 0.0539 - val_loss: 0.0603 - val_mean_absolute_error: 0.0603 - 70s/epoch - 543ms/step\n",
      "\n",
      "Epoch 8/100                                                                     \n",
      "\n",
      "129/129 - 70s - loss: 0.0540 - mean_absolute_error: 0.0540 - val_loss: 0.0637 - val_mean_absolute_error: 0.0637 - 70s/epoch - 541ms/step\n",
      "\n",
      "val_error : 0.059169381856918335                                                \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------[ START 2]-------------------------------------------------------------\n",
      "Parameter : {'input_size': 358, 'lr': 0.003, 'lstm1_dropout': 0, 'lstm1_nodes': 64, 'lstm2_dropout': 0, 'lstm2_nodes': 128, 'num_layers': {'layers': 'three', 'lstm3_dropout': 0.3, 'lstm3_nodes': 128}}\n",
      "Epoch 1/100                                                                       \n",
      "\n",
      "147/147 - 61s - loss: 0.0949 - mean_absolute_error: 0.0949 - val_loss: 0.0574 - val_mean_absolute_error: 0.0574 - 61s/epoch - 414ms/step\n",
      "\n",
      "Epoch 2/100                                                                       \n",
      "\n",
      "147/147 - 51s - loss: 0.0555 - mean_absolute_error: 0.0555 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562 - 51s/epoch - 350ms/step\n",
      "\n",
      "Epoch 3/100                                                                       \n",
      "\n",
      "147/147 - 53s - loss: 0.0539 - mean_absolute_error: 0.0539 - val_loss: 0.0559 - val_mean_absolute_error: 0.0559 - 53s/epoch - 359ms/step\n",
      "\n",
      "Epoch 4/100                                                                       \n",
      "\n",
      "147/147 - 53s - loss: 0.0535 - mean_absolute_error: 0.0535 - val_loss: 0.0558 - val_mean_absolute_error: 0.0558 - 53s/epoch - 360ms/step\n",
      "\n",
      "Epoch 5/100                                                                       \n",
      "\n",
      "147/147 - 55s - loss: 0.0530 - mean_absolute_error: 0.0530 - val_loss: 0.0554 - val_mean_absolute_error: 0.0554 - 55s/epoch - 373ms/step\n",
      "\n",
      "val_error : 0.055359311401844025                                                  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------[ START 3]-------------------------------------------------------------\n",
      "Parameter : {'input_size': 716, 'lr': 0.001, 'lstm1_dropout': 0.3, 'lstm1_nodes': 256, 'lstm2_dropout': 0.3, 'lstm2_nodes': 128, 'num_layers': {'layers': 'three', 'lstm3_dropout': 0, 'lstm3_nodes': 64}}\n",
      "Epoch 1/100                                                                       \n",
      "\n",
      "138/138 - 359s - loss: 0.1417 - mean_absolute_error: 0.1417 - val_loss: 0.0674 - val_mean_absolute_error: 0.0674 - 359s/epoch - 3s/step\n",
      "\n",
      "Epoch 2/100                                                                       \n",
      "\n",
      "138/138 - 395s - loss: 0.0575 - mean_absolute_error: 0.0575 - val_loss: 0.0593 - val_mean_absolute_error: 0.0593 - 395s/epoch - 3s/step\n",
      "\n",
      "Epoch 3/100                                                                       \n",
      "\n",
      "138/138 - 322s - loss: 0.0561 - mean_absolute_error: 0.0561 - val_loss: 0.0576 - val_mean_absolute_error: 0.0576 - 322s/epoch - 2s/step\n",
      "\n",
      "Epoch 4/100                                                                       \n",
      "\n",
      "138/138 - 323s - loss: 0.0545 - mean_absolute_error: 0.0545 - val_loss: 0.0574 - val_mean_absolute_error: 0.0574 - 323s/epoch - 2s/step\n",
      "\n",
      "Epoch 5/100                                                                       \n",
      "\n",
      "138/138 - 343s - loss: 0.0542 - mean_absolute_error: 0.0542 - val_loss: 0.0555 - val_mean_absolute_error: 0.0555 - 343s/epoch - 2s/step\n",
      "\n",
      "Epoch 6/100                                                                       \n",
      "\n",
      "138/138 - 391s - loss: 0.0535 - mean_absolute_error: 0.0535 - val_loss: 0.0550 - val_mean_absolute_error: 0.0550 - 391s/epoch - 3s/step\n",
      "\n",
      "Epoch 7/100                                                                       \n",
      "\n",
      "138/138 - 283s - loss: 0.0531 - mean_absolute_error: 0.0531 - val_loss: 0.0565 - val_mean_absolute_error: 0.0565 - 283s/epoch - 2s/step\n",
      "\n",
      "Epoch 8/100                                                                       \n",
      "\n",
      "138/138 - 245s - loss: 0.0532 - mean_absolute_error: 0.0532 - val_loss: 0.0561 - val_mean_absolute_error: 0.0561 - 245s/epoch - 2s/step\n",
      "\n",
      "val_error : 0.05502846837043762                                                     \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------[ START 4]-------------------------------------------------------------\n",
      "Parameter : {'input_size': 1074, 'lr': 0, 'lstm1_dropout': 0, 'lstm1_nodes': 128, 'lstm2_dropout': 0.3, 'lstm2_nodes': 256, 'num_layers': {'layers': 'three', 'lstm3_dropout': 0.3, 'lstm3_nodes': 32}}\n",
      "Epoch 1/100                                                                         \n",
      "\n",
      "129/129 - 363s - loss: 0.5749 - mean_absolute_error: 0.5749 - val_loss: 0.5864 - val_mean_absolute_error: 0.5864 - 363s/epoch - 3s/step\n",
      "\n",
      "Epoch 2/100                                                                         \n",
      "\n",
      "129/129 - 363s - loss: 0.5749 - mean_absolute_error: 0.5749 - val_loss: 0.5864 - val_mean_absolute_error: 0.5864 - 363s/epoch - 3s/step\n",
      "\n",
      "Epoch 3/100                                                                         \n",
      "\n",
      "129/129 - 361s - loss: 0.5749 - mean_absolute_error: 0.5749 - val_loss: 0.5864 - val_mean_absolute_error: 0.5864 - 361s/epoch - 3s/step\n",
      "\n",
      "Epoch 4/100                                                                         \n",
      "\n",
      "129/129 - 358s - loss: 0.5749 - mean_absolute_error: 0.5749 - val_loss: 0.5864 - val_mean_absolute_error: 0.5864 - 358s/epoch - 3s/step\n",
      "\n",
      "val_error : 0.5864402055740356                                                      \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "100%|██████████| 5/5 [1:27:34<00:00, 1050.96s/trial, best loss: 0.05502846837043762]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "trials = Trials()\n",
    "best = fmin(hyperopt_model,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 5,\n",
    "            trials = trials)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "447de0e7-bc09-4673-9eb3-ce805d6cd5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 1,\n",
       " 'lr': 1,\n",
       " 'lstm1_dropout': 1,\n",
       " 'lstm1_nodes': 2,\n",
       " 'lstm2_dropout': 1,\n",
       " 'lstm2_nodes': 1,\n",
       " 'lstm3_dropout': 0,\n",
       " 'lstm3_nodes': 1,\n",
       " 'num_layers': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6747515-d7a8-4d22-9dd6-f9bf66716fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_size = 358\n",
    "model = Model(data = train,\n",
    "     target = [\"평균기온\"],\n",
    "     input_size = output_size * 2,\n",
    "     output_size = output_size,\n",
    "     test_size = 0.3)\n",
    "train_in, train_out, test_in, test_out = model.Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e198ed7b-1459-4d04-adb1-afd34f56aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_fit(data):\n",
    "    train_in, train_out, test_in, test_out = data\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                                      mode = 'min',\n",
    "                                                      patience = 3,\n",
    "                                                      min_delta = 0.001)\n",
    "    initializer = tf.keras.initializers.GlorotUniform(seed=1234)\n",
    "    lstm_model = tf.keras.Sequential()\n",
    "    lstm_model.add(tf.keras.layers.LSTM(256, return_sequences = True, \n",
    "                                        dropout = 0.3, \n",
    "                                        kernel_initializer=initializer))\n",
    "    lstm_model.add(tf.keras.layers.LSTM(128, return_sequences = True, \n",
    "                                        dropout = 0.3, \n",
    "                                        kernel_initializer=initializer))\n",
    "    lstm_model.add(tf.keras.layers.LSTM(64, return_sequences = False, \n",
    "                                        dropout = 0, \n",
    "                                        kernel_initializer=initializer))\n",
    "    lstm_model.add(tf.keras.layers.Dense(output_size, \n",
    "                                        kernel_initializer=initializer))\n",
    "   \n",
    "    lstm_model.compile(loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "                      metrics = [tf.keras.metrics.mean_absolute_error])\n",
    "    \n",
    "    history = lstm_model.fit(train_in, train_out,\n",
    "                             epochs = 100,\n",
    "                             validation_data = [test_in, test_out],\n",
    "                             callbacks = [early_stopping])\n",
    "    \n",
    "    return lstm_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83b9f9aa-92bc-4df8-9dca-dd19723cdb15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "138/138 [==============================] - 320s 2s/step - loss: 0.2031 - mean_absolute_error: 0.2031 - val_loss: 0.1197 - val_mean_absolute_error: 0.1197\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - 326s 2s/step - loss: 0.0718 - mean_absolute_error: 0.0718 - val_loss: 0.0611 - val_mean_absolute_error: 0.0611\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - 331s 2s/step - loss: 0.0580 - mean_absolute_error: 0.0580 - val_loss: 0.0637 - val_mean_absolute_error: 0.0637\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - 343s 2s/step - loss: 0.0560 - mean_absolute_error: 0.0560 - val_loss: 0.0583 - val_mean_absolute_error: 0.0583\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - 335s 2s/step - loss: 0.0544 - mean_absolute_error: 0.0544 - val_loss: 0.0566 - val_mean_absolute_error: 0.0566\n",
      "Epoch 6/100\n",
      "138/138 [==============================] - 348s 3s/step - loss: 0.0541 - mean_absolute_error: 0.0541 - val_loss: 0.0580 - val_mean_absolute_error: 0.0580\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - 355s 3s/step - loss: 0.0534 - mean_absolute_error: 0.0534 - val_loss: 0.0580 - val_mean_absolute_error: 0.0580\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - 344s 2s/step - loss: 0.0539 - mean_absolute_error: 0.0539 - val_loss: 0.0566 - val_mean_absolute_error: 0.0566\n"
     ]
    }
   ],
   "source": [
    "lstm_model, history = LSTM_fit(model.Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa9ef3a9-cf14-4054-9721-080ca4e6b019",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "_, _, test_in, _ = model.Split(train)\n",
    "_, scaler_out = model.Scale(train)\n",
    "lstm_pred = lstm_model.predict(test_in[-1].reshape(1, (output_size*2), len(train.columns)))\n",
    "lstm_pred = np.round(scaler_out.inverse_transform(lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1a03707-ab2a-4934-a75b-0a2d8fe9d3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7946927374301676"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(train.iloc[-output_size:].평균기온.values, lstm_pred.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a1a16c-dfe4-4519-b48b-09aedacd31e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "adbe0e4a-ab90-48e3-bcf1-4060f8c7faf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_size = 358\n",
    "model = Model(data = train,\n",
    "     target = [\"평균기온\"],\n",
    "     input_size = output_size * 2,\n",
    "     output_size = output_size,\n",
    "     test_size = 0.3)\n",
    "train_in, train_out, test_in, test_out = model.Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5782b43a-1e3d-4d99-b1e6-ca9471501d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU_fit(data):\n",
    "    train_in, train_out, test_in, test_out = data\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                                      mode = 'min',\n",
    "                                                      patience = 3,\n",
    "                                                      min_delta = 0.001)\n",
    "   \n",
    "    initializer = tf.keras.initializers.GlorotUniform(seed=1234)\n",
    "    lstm_model = tf.keras.Sequential()\n",
    "    lstm_model.add(tf.keras.layers.GRU(128, return_sequences = True, \n",
    "                                        kernel_initializer=initializer))\n",
    "    lstm_model.add(tf.keras.layers.GRU(128, return_sequences = True, \n",
    "                                        kernel_initializer=initializer))\n",
    "    lstm_model.add(tf.keras.layers.GRU(128, return_sequences = False, \n",
    "                                        kernel_initializer=initializer))\n",
    "    lstm_model.add(tf.keras.layers.Dense(output_size))\n",
    "   \n",
    "    lstm_model.compile(loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "                      metrics = [tf.keras.metrics.mean_absolute_error])\n",
    "    \n",
    "    history = lstm_model.fit(train_in, train_out,\n",
    "                             epochs = 100,\n",
    "                             validation_data = [test_in, test_out],\n",
    "                             callbacks = [early_stopping])\n",
    "    \n",
    "    return lstm_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ab4786c-418a-48e7-8855-dcc664fe7afa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "540/540 [==============================] - 714s 1s/step - loss: 0.0711 - mean_absolute_error: 0.0711 - val_loss: 0.0550 - val_mean_absolute_error: 0.0550\n",
      "Epoch 2/100\n",
      "540/540 [==============================] - 705s 1s/step - loss: 0.0514 - mean_absolute_error: 0.0514 - val_loss: 0.0543 - val_mean_absolute_error: 0.0543\n",
      "Epoch 3/100\n",
      "540/540 [==============================] - 717s 1s/step - loss: 0.0509 - mean_absolute_error: 0.0509 - val_loss: 0.0530 - val_mean_absolute_error: 0.0530\n",
      "Epoch 4/100\n",
      "540/540 [==============================] - 703s 1s/step - loss: 0.0506 - mean_absolute_error: 0.0506 - val_loss: 0.0533 - val_mean_absolute_error: 0.0533\n",
      "Epoch 5/100\n",
      "540/540 [==============================] - 710s 1s/step - loss: 0.0502 - mean_absolute_error: 0.0502 - val_loss: 0.0543 - val_mean_absolute_error: 0.0543\n",
      "Epoch 6/100\n",
      "540/540 [==============================] - 707s 1s/step - loss: 0.0496 - mean_absolute_error: 0.0496 - val_loss: 0.0524 - val_mean_absolute_error: 0.0524\n"
     ]
    }
   ],
   "source": [
    "GRU_model, history = GRU_fit(model.Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc4dd830-225b-4548-8fa4-694480b510c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8438547486033516"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, test_in, _ = model.Split(train)\n",
    "_, scaler_out = model.Scale(train)\n",
    "gru_pred = GRU_model.predict(test_in[-1].reshape(1, (output_size*2), len(train.columns)))\n",
    "gru_pred = np.round(scaler_out.inverse_transform(gru_pred))\n",
    "mean_absolute_error(train.iloc[-output_size:].평균기온.values, gru_pred.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bdd2b2-2f3c-4bac-ab19-c984bf84c587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4414b-b9c3-46df-8865-6d7b63ba871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"data/sample_submission.csv\")\n",
    "scale_data, scaler_in, scaler_out = model.Scale(train)\n",
    "pred = GRU_model.predict(scale_data[-(output_size*2):].values.reshape(1, (output_size*2), 13))\n",
    "pred = np.round(scaler.inverse_transform(pred))\n",
    "sub.평균기온 = pred[0]\n",
    "sub.to_csv(\"data/GRU_128_128_128.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83ccc6-3086-4832-86ac-f2ad19d0e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/ourownstory/neural_prophet.git\n",
    "from neuralprophet import NeuralProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb4c0b-d0a2-4321-be05-726fab112788",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "# 이상치 판단\n",
    "def outlier(data, column):\n",
    "    q25 = np.quantile(data[column].dropna(), 0.25)\n",
    "    q75 = np.quantile(data[column].dropna(), 0.75)\n",
    "    iqr = q75 - q25\n",
    "    iqr_cut = iqr * 3\n",
    "    result = data[(data[column] > q75 + iqr_cut) | (data[column] < q25 - iqr_cut)].index\n",
    "    return result\n",
    "\n",
    "# 보간\n",
    "def time_interpolate(data, column):\n",
    "    tem = data[[\"일시\", column]].copy()\n",
    "    tem.index = pd.to_datetime(tem['일시'])\n",
    "    tem = tem.drop([\"일시\"], axis = 1)\n",
    "    tem = tem.interpolate(method=\"time\")\n",
    "    return tem[column].values\n",
    "\n",
    "# 강수량은 기상청에서 정한 강수표현에 따라 구간을 나누는 것으로 수치 변경\n",
    "# 비가 내리지 않음 : 0, 매우 약한 비 : 0~1, 약한 비 : 1~3, 보통 비 : 3~15, 강한 비 : 15~30, 매우 강한 비 : 30 이상\n",
    "train.강수량 = pd.cut(train.강수량, bins = [0, 0.9, 2.9, 14.9, 29.9, max(train.강수량)], labels = [1, 2, 3, 4, 5])\n",
    "train.강수량 = train.강수량.astype('float')\n",
    "train.강수량 = train.강수량.fillna(0)\n",
    "\n",
    "rain = pd.get_dummies(train.강수량)\n",
    "rain.columns = [\"비안내림\", \"매우약한비\", \"약한비\", \"보통비\", \"강한비\", \"매우강한비\"]\n",
    "train = pd.concat([train, rain.astype(\"int\")], axis=1)\n",
    "train = train.drop([\"강수량\"], axis = 1)\n",
    "\n",
    "train.최고기온 = time_interpolate(train, \"최고기온\")\n",
    "train.최저기온 = time_interpolate(train, \"최저기온\")\n",
    "\n",
    "train.일교차 = train.최고기온 - train.최저기온\n",
    "\n",
    "train.평균풍속 = time_interpolate(train, \"평균풍속\")\n",
    "\n",
    "train.일조합 = time_interpolate(train, \"일조합\")\n",
    "\n",
    "train.loc[0:4749, \"일사합\"] = 0\n",
    "train.loc[4780:4854, \"일사합\"] = 0\n",
    "train.일사합 = time_interpolate(train, \"일사합\")\n",
    "\n",
    "\n",
    "# 삭제\n",
    "train = train.iloc[train.일조율.dropna().index]\n",
    "\n",
    "# 가조합\n",
    "train[\"가조합\"] = train.일조합/(train.일조율/100)\n",
    "train.가조합 = [np.nan if i == float(\"inf\") else i for i in train.가조합]\n",
    "train.가조합 = time_interpolate(train, \"가조합\")\n",
    "\n",
    "# 일사합/일조합\n",
    "train[\"일사_일조\"] = train.일사합/train.일조합\n",
    "train.일사_일조 = [np.nan if i == float(\"inf\") else i for i in train.일사_일조] # 분모가 0인 경우 임의로 값을 설정할 수 없어 보간으로 처리\n",
    "train.일사_일조 = time_interpolate(train, \"일사_일조\")\n",
    "\n",
    "# sin + cos\n",
    "train[\"sin_cos\"] = [-np.sin(2 * np.pi * int(datetime.strptime(i,\"%Y-%m-%d\").strftime(\"%j\"))/365) - np.cos(2 * np.pi * int(datetime.strptime(i,\"%Y-%m-%d\").strftime(\"%j\"))/365) for i in train.일시]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa19e7be-41e7-46b7-a1f4-a9d8a217459c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일시</th>\n",
       "      <th>최고기온</th>\n",
       "      <th>최저기온</th>\n",
       "      <th>일교차</th>\n",
       "      <th>강수량</th>\n",
       "      <th>평균습도</th>\n",
       "      <th>평균풍속</th>\n",
       "      <th>일조합</th>\n",
       "      <th>일사합</th>\n",
       "      <th>일조율</th>\n",
       "      <th>평균기온</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>2.2</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-01-02</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>87.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-01-03</td>\n",
       "      <td>8.7</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960-01-04</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-01-05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23006</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.25</td>\n",
       "      <td>91.7</td>\n",
       "      <td>-2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23007</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>58.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.86</td>\n",
       "      <td>90.6</td>\n",
       "      <td>-3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23008</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.88</td>\n",
       "      <td>93.8</td>\n",
       "      <td>-2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23009</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>10.84</td>\n",
       "      <td>82.3</td>\n",
       "      <td>-1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23010</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.16</td>\n",
       "      <td>11.5</td>\n",
       "      <td>-1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23011 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               일시  최고기온  최저기온   일교차  강수량  평균습도  평균풍속  일조합    일사합   일조율  평균기온\n",
       "0      1960-01-01   2.2  -5.2   7.4  0.0  68.3   1.7  6.7   0.00   0.0  -1.6\n",
       "1      1960-01-02   1.2  -5.6   6.8  0.4  87.7   1.3  0.0   0.00   0.0  -1.9\n",
       "2      1960-01-03   8.7  -2.1  10.8  0.0  81.3   3.0  0.0   0.00   0.0   4.0\n",
       "3      1960-01-04  10.8   1.2   9.6  0.0  79.7   4.4  2.6   0.00   0.0   7.5\n",
       "4      1960-01-05   1.3  -8.2   9.5  0.0  44.0   5.1  8.2   0.00   0.0  -4.6\n",
       "...           ...   ...   ...   ...  ...   ...   ...  ...    ...   ...   ...\n",
       "23006  2022-12-27   3.3  -7.3  10.6  0.0  69.8   1.8  8.8  10.25  91.7  -2.6\n",
       "23007  2022-12-28   0.1  -6.0   6.1  0.1  58.1   2.5  8.7  10.86  90.6  -3.3\n",
       "23008  2022-12-29   2.1  -7.8   9.9  0.0  56.3   1.7  9.0  10.88  93.8  -2.9\n",
       "23009  2022-12-30   2.3  -4.4   6.7  0.0  65.6   1.9  7.9  10.84  82.3  -1.8\n",
       "23010  2022-12-31   2.1  -5.1   7.2  0.0  65.5   1.4  1.1   4.16  11.5  -1.2\n",
       "\n",
       "[23011 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train = train.fillna(0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72802cfb-1e02-4e76-b844-677309460893",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[16071:]\n",
    "\n",
    "\n",
    "train['일시'] = pd.to_datetime(train['일시'])\n",
    "train = train.set_index('일시')\n",
    "\n",
    "# 데이터의 시간 간격 지정\n",
    "train.index.freq = 'D'\n",
    "train = train.reset_index()\n",
    "train = train.rename(columns={'일시': 'ds', '평균기온': 'y'})\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "train_c = train.copy()\n",
    "i = int(len(train)*0.8)\n",
    "train = train_c.iloc[:i]\n",
    "test = train_c.iloc[i:]\n",
    "\n",
    "col_lst=train.columns\n",
    "col_lst=col_lst.drop(['ds','y'])\n",
    "col_lst=list(col_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aeeb9b-1fa8-42a7-80a5-bcaa1be21de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "\n",
    "growth='off', # 추세 유형 설정(linear, discontinuous, off 중 선택 가능)\n",
    "n_forecasts=358,\n",
    "yearly_seasonality=True, #년간 계절성 설정\n",
    "\n",
    "weekly_seasonality=False, #주간 계절성 설정\n",
    "\n",
    "daily_seasonality=False, #일간 계절성 설정\n",
    "\n",
    "epochs=100,#학습 횟수 설정\n",
    "\n",
    "learning_rate=0.1\n",
    ")\n",
    "\n",
    "#독립 변인(변수) 추가 및 정규화\n",
    "m = m.add_lagged_regressor(names=col_lst, normalize=\"minmax\") \n",
    "\n",
    "#학습 수행\n",
    "metrics = m.fit(train, freq='D', validation_df=test, progress='plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b07d5-f0e3-4877-9714-6e642aab17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE(Train): \", metrics.MAE.tail(1).item())\n",
    "print(\"MAE(Test): \", metrics.MAE_val.tail(1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc5f57-d928-4acf-b34f-3922aedf3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#future = metrics.make_future_dataframe(test, periods=358)\n",
    "#pred = metrics.predict(future)\n",
    "pred = metrics.predict(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
